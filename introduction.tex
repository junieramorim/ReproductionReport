By their nature, military operations require coordination among different elements forming a team engaged in the activities on the field and an optimized use of the available resources~\citep{CC01}. For particularly dangerous missions, it is becoming usual the employment  of Unmanned Aerial Vehicles (\uav) equipped with some devices and different levels of available resources~\citep{nonami2010autonomous}~\citep{UAV01}, as well as an efficient navigation and positioning system~\citep{UAV10}. However, it is necessary to consider limitations in these resources, e.g., levels of battery or fuel, as well as number and type of sensors on board. Thereby, when a team of UAVs has a certain level of autonomy, it needs to plan the execution of the tasks necessary to accomplish a given mission, observing an optimized usage of the available resources in order to increase the probability of mission accomplishment. This planning can be addressed as a task allocation problem.

To deal with this allocation problem in a decentralized way, there is a heuristic method for task allocation based on swarm intelligence called Swarm-GAP~\citep{ferreira2007swarm}, in which there is no central command unit that has global context knowledge. According to this strategy, as shown in~\citep{MOEA07} and~\citep{MOEA05}, the decision is taken and shared among the agents based only in local information of each one.

Although Swarm-GAP presents overall good results, there are some drawbacks in its token passing mechanism when there are many tasks on it. This aspect limits the task allocation even if the UAV has available resources, which is a problem addressed in~\citep{MOEA07} and~\citep{MAS07}. This issue can occur in some situations, e.g., the information exchange among UAVs can get into loop. Thereby, the original study done by \textit{Schwarzrock et al.}~\citep{MAS07}, which is the basis for this current work, proposed three variants of the Swarm-GAP algorithm in order to mitigate the previously mentioned issue.

An important assumption adopted by the original work is that the context in the addressed scenario is static, i.e., there is no change in the scenario during mission execution. The original algorithm variants in~\citep{MAS07} analyze the on board resources, e.g. VGA camera, thermal and infrared sensors, to allocate the suitable tasks to the agents aiming at the maximization of the results related to the quality associated to the mission accomplishment. This quality is represented by attributes, e.g., time to mission accomplish, total resources used, resources compatibility with the tasks to be performed.

Although the lack of evidence that the three variants presented in~\citep{MAS07} work on a dynamic context, the authors presented the hypothesis that these algorithms may work in dynamic scenarios based on their architecture and logical structure. However, their design were made focused on the assumption of a static scenario with no changes during runtime. Thus, despite the statement of the possible application of that approach to dynamic scenarios, there is no evidence that confirms it.

On the other hand, dynamism is a recurrent aspect in all military operations, and it brings a high impact level to the results and to the operation itself, as explained in~\citep{CC02}. Changes in the mission and in the team itself are some dynamic elements in this context requiring a reorganization and coordination of the agents to get an adaptation to the new scenario to keep key quality attributes within an acceptable level~\citep{FRANCE2014}. 

In light of this landscape, the purpose of this work is two-fold: 1) Replicate, in a dynamic context, the original experiment~\citep{MAS07}; 2) Based on the findings of such replication, extend the original algorithms to better address the dynamic scenarios. The considered dynamism was represented by randomly shutting down some agents during the mission execution.

Indeed, despite the suggestion by the independent replication that the original algorithms work~\citep{MAS07} in a dynamic scenario, it was observed degradation in the results associated to the quality of the mission execution. Thus, this work extends the algorithms proposed by \textit{Schwarzrock et al.} to mitigate these losses suffered due to the effects of the scenario dynamism.

The empirical assessment relied on experiment replication complying with the rules presented in~\citep{exp01},~\citep{exp03}, and~\citep{exp04}. The replications follow the same conditions of the original work with the addition of the dynamism in the number of agents performing the mission. The first replication assessed the original algorithms, whereas the second one assessed their extension presented in this work. In either case, the outcomes are extracted to identify the differences in terms of quality and communication overhead.

In summary, the contributions of this paper are the following:

\begin{itemize}
   \item The performance of an independent replication to evaluate the original algorithms in a dynamic scenario. (Section~\ref{sec:original});
   \item Based on the results acquired with the replication of the original algorithms, improvements were proposed to better address the new dynamic scenario (Section \ref{sec:changes});
   \item An empirical assessment of the newly proposed algorithms along with the original one in the dynamic scenario exploring and discussing trade-offs (Section \ref{sec:replication}).
\end{itemize}

The remainder of this paper is organized as follows. In Section \ref{sec:background}, the concepts involved during the replication are briefly presented. Section \ref{sec:method} presents the experimental setup, describing the analysis of the original algorithms, a dynamic scenario, and proposed extended algorithms. The replications performed with the original and the extended algorithms are presented in Section \ref{sec:replications}. Section \ref{sec:discussion} analyzes the results obtained by the replications identifying emerging trade-off, research validity threats, and future work opportunities. Section \ref{sec:related_works} discusses related work. The concluding remarks are done in Section \ref{sec:conclusions}.