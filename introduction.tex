By their nature, military operations require coordination among different elements forming a team engaged in the activities on the field and an optimized use of the available resources \cite{CC01}. For particularly dangerous missions, it is becoming usual the employment  of Unmanned Aerial Vehicles (\uav) equipped with different level of devices and available resources \cite{nonami2010autonomous} \cite{UAV01}. However, it is necessary to consider limitations in these resources, e.g. levels of battery or fuel, as well as number and type of sensors on board. Thereby, when a team of UAVs has a certain level of autonomy, it needs to plan the execution of the tasks necessary to accomplish a given mission, observing an optimized usage of the available resources in order to increase the probability of the mission accomplishment. This planning can be addressed as a task allocation problem.

To deal with this allocation problem in a decentralized way, there is a heuristic method for task allocation based on swarm intelligence called Swarm-GAP\cite{ferreira2007swarm}, in which there is no central command unit that has global context knowledge. According to this strategy, as shown in \cite{MOEA07} and \cite{MOEA05}, the decision is taken and shared among the agents based only in local information of each one .

Although Swarm-GAP presents overall good results, there are some drawbacks in its token passing mechanism when there are many tasks on it. This aspect limits the task allocation even if the UAV has available resources, which is a problem addressed in \cite{MOEA07} and \cite{MAS07}. This issue can occur in some situations, e.g., the information exchange among UAVs can get into loop. Thereby, the original study done by \textit{Schwarzrock et al.} (2017)\cite{MAS07}, which is the basis for this current work, proposed three adaptations of Swarm-GAP algorithm in order to mitigate the previously mentioned issue .

An important assumption adopted by the original work is that the context in the addressed scenario is static, i.e. there is no change in the scenario during mission execution. The original algorithm variants in \cite{MAS07} analyze the on board resources, e.g. VGA camera, thermal and infrared sensors, to allocate the suitable tasks to the agents aiming at the maximization of the results related to the quality associated to the mission accomplishment. 

Although the lack of evidence that the three variants presented in \cite{MAS07} work on a dynamic context, the authors presented the hypothesis that these algorithms may work in dynamic scenarios based on their architecture and logical structure. However, their design were made focused on the assumption of a static scenario with no changes during runtime. Thus, despite the statement of the possible application of that approach to dynamic scenarios, there is no evidence that confirms it.

Dynamism is a recurrent aspect in all military operations, and it brings a high impact level to the results and to the operation itself, as explained in \cite{CC02}. Changes in the mission and in the team itself are some dynamic elements in this context requiring a reorganization and coordination of the agents to get an adaptation to the new scenario to keep key quality attributes within an acceptable level \cite{FRANCE2014}. 

In light of this landscape, the purpose and main contributions of this work are two-fold: 1) First it aims to show the results obtained with the independent replication of the original experiment presented by \cite{MAS07}, but considering dynamic scenarios; 2) Based on the findings from the experiments with dynamic scenarios, to propose improvements to the original algorithm to better address the dynamic scenarios. The considered dynamism was represented by randomly shutting down some agents during the mission execution. The results were collected to analyze the performance of the algorithms facing this new unstable scenario.

Despite the suggestion by the independent replication that the original algorithms work \cite{MAS07} on a dynamic scenario, it was observed degradation in the results results associated to the quality of the mission execution. Thus, this work additionally extends the algorithms proposed by \textit{Schwarzrock et al.} to mitigate these losses suffered due to the effects of the scenario dynamism.

All the results validation and evaluation were obtained through experiment replication following the rules presented in \cite{exp01}, \cite{exp03} and \cite{exp04}. The experiment follows the same conditions of the original work with the addition of the dynamism in the number of agents performing the mission. These experiments were done with the original algorithm and the new proposal here presented. The outcomes are extracted to identify the differences in terms of quality and communication overhead.

In summary, the contributions of this paper are the following:

\begin{itemize}
   \item The performance of an independent replication to evaluate the original algorithms in a dynamic scenario. (Section \ref{sec:dynamic_scenario});
   \item Based on the results acquired with the replication of the original algorithms, improvements were proposed to better address the new dynamic scenario (Section \ref{sec:evaluation});
   \item An empirical assessment of the new proposed algorithm along with the original one in the dynamic scenario exploring and discussing trade-offs (Section \ref{sec:discussion}).
\end{itemize}

The remainder of this paper is organized as follows. In Section \ref{sec:background}, the concepts involved during the replication is briefly presented. Section \ref{sec:method} presents the experimental setup, describing the analysis of the original algorithms, and the dynamic context and extended algorithms proposed. The replications performed with the original and the extended algorithms are presented in Section \ref{sec:replications}. Section \ref{sec:discussion} analyzes the results obtained by the replications identifying emerging trade-off, the research validity threats and the future works opportunities. Section \ref{sec:related_works} discusses related work. The concluding remarks are done in Section \ref{sec:conclusions}.