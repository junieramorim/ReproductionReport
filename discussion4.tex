%Threats to validity
% scenario more dynamic
% other variables change

Basically, the methodology applied in our study was independent replications to collect results to find evidence that the original and extended algorithms are suitable to address the dynamic context. All assessment was done based on these results measured. Thus, for this process we present the threats to validity below: 

\begin{itemize}
   \item \textbf{Conclusion validity}: We used the same code of the original study but during the experiments it was obtained different results that, although they were in standard deviation when compared with previous work, it indicates a variance possibility with changes in the experiment environment. These variations could be increased in case of code changes to implement dynamism. To minimize this threat, we performed a set of tests and analysis using a debug process to minimize undesirable responses due to a bad code manipulation after implement dynamism with changes in the number of agents. The results were analyzed to verify correlation and coherence with the new dynamic condition. As the results collected can varies depending on the hardware capability, each algorithm was executed a hundred times to reduce the results' standard deviation. Furthermore, to compare means, apparently equals to each other, we used a t-Test to identify these minor differences among them in the results with different algorithms proposed, after analyzing their similarity with a normal distribution.
   \item \textbf{Internal validity}: The performance of each algorithm depends on the execution environment. Since the machine configuration and the tool version used (NetLogo 5.3.1) uses some operational system libraries, there are a slight difference in the results obtained with different hardware and software. To minimize this impact, we performed a reproduction of the original study \cite{MAS07} to have a suitable result set to be used as reference values in experiments comparison.
   \item \textbf{Construct validity}: All replications performed used the code obtained with the researcher of the original study, and the documentation lack became an issue in the moment of experiment execution. The modifications done, to create our dynamic scenario, could generate collateral effects not identified that could hide some influences and produce non-consistent results. To mitigate this threat, we performed tests and analysis using a debug process to minimize undesirable responses due to a bad code manipulation. Besides that, we used the same dependent variables, units and measurement procedure from the original work, obtaining the results directly from the simulation tool(NetLogo 5.3.1).
   \item \textbf{External validity}: The extended algorithms here proposed were applied in a dynamic context where only the number of agents changes. Although the algorithms presented a good performance in this scenario, we know that other elements can change in a real world. The number of tasks, kind of tasks, health of sensors onboard and other context issues can occurs in a real scenario. However, it was possible to approximate the original study, made in a static context, to something closer to the real world. This improvement permits an approach using Swarm-GAP intelligence in a context with a certain level of dynamism.
\end{itemize}

