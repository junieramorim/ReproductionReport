The works presented by \textit{Alighanbari and How}\cite{alighanbari2005decentralized} and \textit{Schwarzrock et al.}\cite{MAS07} provide the task assignment for a fleet of UAVs, having a decentralized structure with no central command, and running only in static scenarios. The algorithms presented by them were not tested in scenarios were changes may occur during  execution time, e.g., the number of agents or tasks changes while the mission is being performed. However, both works mentioned the need of tasks' reassignment in case of any  change in the scenario, leaving investigations about this topic as future work. This idea was used in our study to suggest a token reset by the algorithm to address dynamic scenarios.

Our work presents a proposal inspired in what was proposed by \textit{Schwarzrock et al.}\cite{MAS07} and topics related with tasks allocation and Multi-Agent Systems(MAS) presented by other authors \cite{MAS01, MAS02, MAS03, MAS04, MAS05, MAS06}, extending applied concepts to dynamic scenarios. Although there are centralized solutions to this problem, such as what was presented by \textit{Jose and Pratihar}\cite{jose2016task}, that uses genetic algorithm to assign tasks to a set of robots in a inspection system, this kind of solution is not suitable in the context here considered because it would imply in a single point of failure, which is an undesirable weakness for military systems.

Multiobjective Optimization Problems (MOP) are represented by a vector of decisions satisfying some constraints and aim to optimize a vector of functions that represents an objective. The number of constraints must be less or equal to the number of elements in the decision vector, otherwise it is created a problem called as over-constrained. In this scenario, as shown by Coello et al.\cite{MOEA01},  multiobjective evolutionary algorithms (MOEA) appear as a powerful tool to analyze all objectives and their constraints, maximizing global results. This optimization is done with rounds of data analysis trying to converge to the better response. Zitzler et al.\cite{07} compared some approaches to solve MOP and it is possible to identify a common characteristic in the communication protocol that defines a way to redistribute the functions aiming to optimize results. We used this strategy applying more than one communication round in the extended algorithms here proposed.

Ferreira et al. \cite{ferreira2007swarm} provided evidence that the $stimulus$ value of $0.6$ generates best results when applied to calculate the capability of task execution by the agent. However, that analysis was done based on a static scenario. Our work identified a slight difference of $\simeq 3\%$ in results when applied different $stimulus$ in dynamic scenarios. For a fair comparison with the original study presented in \cite{MAS07}, and considering the small difference in results, the value of $0.6$ was adopted for this variable.

Many works \cite{ferreira2007swarm,scerri2005allocatingLADCOP, ferreira2010robocup,ikemoto2010adaptive} deal with the allocation task problem. In those studies, the organization and tasks ordering are done by a central command unit. However, this strategy generates a huge amount of messages to transmit the tasks and it can imply in a great communication overhead. Moreover, a central command unit represent a single point of failure. To deal with this, the strategy adopted by \textit{Schwarzrock et al.}\cite{MAS07} was the Swarm-GAP, so that it is easier to add agents in the structure or even to treat onboard sensors issues. Our work follows the same strategy based on the requirement of decentralized structure of decision using swarm intelligence.